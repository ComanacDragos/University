\subsection{Comparison with other methods}
    State of the art object detection models such as YOLOv4 \cite{yolov4} achieve real-time performance and overall good detection accuracy. We use the COCO dataset \cite{coco} in order to compare our method with other existent methods. This dataset has several splits such as validation or test-dev. We test our method by performing object detection on each of these dataset splits and uploading the results to the evaluation server. We follow the guidelines regarding the data format described on the official website, where details about the evaluation server are also provided. 
    
    On this dataset, the YOLO state of the art detector achieves 43.9\% mAP, SSD achieves 25.1\% mAP, and the currently best mAP on the detection competition leaderboard is 63\%. Our method achieves a modest 0.4\% mAP on the test-dev bounding box evaluation server, indicating that there is still room for improvement. This performance might be due to the fact that our method was developed considering only three classes, and the COCO dataset has 80 classes. We also tried to develop a very small model because the resources are limited on a mobile device. For example, our model has around 14 megabytes, whereas better object detectors have around 200-300 megabytes or more. Also, the hyperparameters are not tuned for this specific dataset.
    
    Using our own measurement, which is based on the official PASCAL VOC mAP implementation \cite{pascal-voc-2007}, we achieve 28\% mAP on the validation set. We did this computation on the validation set because the ground truth annotations are not publicly available for the test set.
  
    Regarding speed, on the same mobile device, a method based on MobileNet \cite{mobilenetv2} and SSD \cite{ssd} achieves around 80 milliseconds (ms) per frame, while our method achieves around 190 ms per frame.
